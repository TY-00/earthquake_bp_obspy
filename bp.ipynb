{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################################\n",
    "# ADD SOME GENERAL INFO and LICENSE -> @ajay6763\n",
    "##########################################################################\n",
    "from __future__ import division\n",
    "import sys\n",
    "import obspy\n",
    "from obspy.taup import TauPyModel\n",
    "from obspy.geodetics import locations2degrees\n",
    "from obspy.geodetics.base import gps2dist_azimuth\n",
    "from obspy.signal.trigger import recursive_sta_lta_py\n",
    "from scipy import signal\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.tri import Triangulation\n",
    "import matplotlib.transforms as mtransforms\n",
    "########### \n",
    "#import bp lib\n",
    "import bp_lib as bp_lib\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kumar\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\obspy\\io\\stationxml\\core.py:98: UserWarning: The StationXML file has version 1, ObsPy can read versions (1.0, 1.1). Proceed with caution.\n",
      "  version, \", \".join(READABLE_VERSIONS)))\n",
      "c:\\users\\kumar\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\obspy\\io\\stationxml\\core.py:98: UserWarning: The StationXML file has version 1, ObsPy can read versions (1.0, 1.1). Proceed with caution.\n",
      "  version, \", \".join(READABLE_VERSIONS)))\n",
      "c:\\users\\kumar\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\obspy\\io\\stationxml\\core.py:98: UserWarning: The StationXML file has version 1, ObsPy can read versions (1.0, 1.1). Proceed with caution.\n",
      "  version, \", \".join(READABLE_VERSIONS)))\n"
     ]
    }
   ],
   "source": [
    "##########################################################################\n",
    "# Event info\n",
    "##########################################################################\n",
    "origin_time          = obspy.UTCDateTime(2016, 1, 3, 23, 5, 22)\n",
    "event_lat            = 24.80360\n",
    "event_long           = 93.65050\n",
    "event_depth          = 55.0 # km\n",
    "##########################################################################\n",
    "# data info\n",
    "##########################################################################\n",
    "Array_name           = 'AU_test'\n",
    "stations             = './data/test/bp_stations_'+str(Array_name)+'/*'\n",
    "inv                  = obspy.read_inventory(stations)\n",
    "wavefroms            = './data/test/bp_waveforms_'+str(Array_name)+'/*.mseed'\n",
    "\n",
    "stream_orig          = obspy.read(wavefroms)\n",
    "stream_work          = stream_orig.copy()\n",
    "##########################################################################\n",
    "# BP parameters\n",
    "##########################################################################\n",
    "model = TauPyModel(model=\"ak135\")\n",
    "#model               = TauPyModel(model=\"iasp91\")\n",
    "Start_P_cut_time    = 60  #before P arrival in seconds\n",
    "End_P_cut_time      = 120 #After P arrival seconds\n",
    "sps                 = 20  #samples per seconds\n",
    "bp_l                = 0.2 #Hz\n",
    "bp_u                = 5   #Hz\n",
    "stack_start         = 0   #in seconds\n",
    "stack_end           = 60  #in seconds\n",
    "smooth_time_window  = 5   #seconds\n",
    "source_grid_size    = 0.5 #degrees\n",
    "source_grid_extend  = 2   #degrees\n",
    "min_distance        = 30  #degrees\n",
    "max_distance        = 90  #degress\n",
    "##########################################################################\n",
    "# Making potential sources grid\n",
    "##########################################################################\n",
    "slong,slat          = bp_lib.make_source_grid(event_long,event_lat,source_grid_extend,source_grid_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of stations: 104\n"
     ]
    }
   ],
   "source": [
    "##########################################################################\n",
    "# Load stations inventory\n",
    "##########################################################################\n",
    "# Loading the station inventory and data for AU network\n",
    "# Getting stations name, lat, and longs in a list\n",
    "# This is done to make a lookup such that when I read the traces\n",
    "# I can figure out the locations of those traces.\n",
    "# What I do not understand is why the station and event is not\n",
    "# included into the trace.stats, like we have in sac.\n",
    "# May be I am missing something when I download or\n",
    "# there is clever way or function do this.\n",
    "sta_net             = []\n",
    "sta_name            = []\n",
    "sta_lat             = []\n",
    "sta_long            = []\n",
    "sta_dist            = []\n",
    "sta_azimuth         = []\n",
    "sta_P_arrival_taup  = []\n",
    "for net in inv:\n",
    "    for sta in net:\n",
    "        sta_name.append(sta.code)\n",
    "        sta_net.append(net.code)\n",
    "        for channels in sta:\n",
    "                sta_lat.append(channels.latitude)\n",
    "                sta_long.append(channels.longitude)\n",
    "                sta_dist.append(locations2degrees(event_lat,event_long,channels.latitude,channels.longitude))\n",
    "                s1,s2,s3=gps2dist_azimuth(event_lat,event_long,channels.latitude,channels.longitude, a=6378137.0, f=0.0033528106647474805)\n",
    "                sta_azimuth.append(s3)\n",
    "                #arrivals       = model.get_travel_times(source_depth_in_km=event_depth,distance_in_degree=locations2degrees(event_lat,event_long,channels.latitude,channels.longitude),phase_list=[\"P\"])\n",
    "                #arr            = arrivals[0]\n",
    "                #t_travel       = arr.time;\n",
    "                #sta_P_arrival_taup.append(t_travel)\n",
    "print('Total number of stations:', len(sta_lat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total no stations with data: 104\n",
      "Sampling rate of the waveform data: [  20.   40.   50.  100.]\n"
     ]
    }
   ],
   "source": [
    "##########################################################################\n",
    "# reading wavefrom data and assigning station info to them \n",
    "# I do this by haveing lists of stations with all the info read and \n",
    "# extracted above and then look-up for the station name in the waveform\n",
    "# and doing the assignment\n",
    "##########################################################################\n",
    "# Looping through the network traces and writing \n",
    "# station latitude and station longitude \n",
    "sta_sps=[]\n",
    "for t in stream_work:\n",
    "        sta          = t.stats.station\n",
    "        if sta in sta_name:\n",
    "            ind                          = sta_name.index(sta)\n",
    "            t.stats['Dist']              = sta_dist[ind]\n",
    "            t.stats['Azimuth']           = sta_azimuth[ind]\n",
    "            t.stats['station_latitude']  = sta_lat[ind]\n",
    "            t.stats['station_longitude'] = sta_long[ind]\n",
    "            t.stats['origin_time']       = origin_time\n",
    "            arrivals                     = model.get_travel_times(source_depth_in_km=event_depth,distance_in_degree=locations2degrees(event_lat,event_long,sta_lat[ind],sta_long[ind]),phase_list=[\"P\"])\n",
    "            arr                          = arrivals[0]\n",
    "            t_travel                     = arr.time;\n",
    "            t.stats['P_arrival']         = origin_time + t_travel \n",
    "            sta_sps.append(t.stats.sampling_rate)\n",
    "        else:\n",
    "            stream_work.remove(t)\n",
    "print(\"Total no stations with data:\", len(stream_work))\n",
    "print(\"Sampling rate of the waveform data:\", np.unique(sta_sps))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total no of traces before decimation criteria: 104\n",
      "Total no of traces after decimation criteria: 73\n"
     ]
    }
   ],
   "source": [
    "##########################################################################\n",
    "# SPS and distance check\n",
    "##########################################################################\n",
    "# make a copy of the data and leave the original\n",
    "print('Total no of traces before decimation criteria:', len(stream_work))\n",
    "for t in stream_work:\n",
    "    if (t.stats.sampling_rate==20. or t.stats.sampling_rate==40. or t.stats.sampling_rate==80.\n",
    "        or t.stats.sampling_rate==100. or t.stats.sampling_rate==120. or t.stats.sampling_rate==200.):\n",
    "        pass\n",
    "    else:\n",
    "        stream_work.remove(t)\n",
    "######### decimating\n",
    "for t in stream_work:\n",
    "    if (t.stats.sampling_rate   == 20.):\n",
    "        pass\n",
    "    elif (t.stats.sampling_rate == 40.):\n",
    "        t.decimate(2)\n",
    "    elif (t.stats.sampling_rate == 50.):\n",
    "        t.resample(20.0)\n",
    "    elif (t.stats.sampling_rate == 80.):\n",
    "        t.decimate(4)\n",
    "    elif (t.stats.sampling_rate == 100.):\n",
    "        t.decimate(5)\n",
    "    elif (t.stats.sampling_rate == 120.):\n",
    "        t.decimate(6)\n",
    "    elif (t.stats.sampling_rate == 200.):\n",
    "        t.decimate(10)\n",
    "    else:\n",
    "        print(\"There are some traces that cannot be decimated 20 SPS. Please check the SPS of your data\")\n",
    "        sys.exit(...)\n",
    "print('Total no of traces after decimation criteria:', len(stream_work))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total no of traces before  distance criteria: 73\n",
      "Total no of traces after distance criteria: 70\n"
     ]
    }
   ],
   "source": [
    "print('Total no of traces before  distance criteria:', len(stream_work))\n",
    "for t in stream_work:\n",
    "    if (t.stats.Dist > min_distance and t.stats.Dist < max_distance):\n",
    "        pass\n",
    "    else:\n",
    "        stream_work.remove(t)\n",
    "print('Total no of traces after distance criteria:', len(stream_work))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################################\n",
    "# CUtting 30 seconds before P arrival and 120 seconds after and filter\n",
    "##########################################################################\n",
    "stream_cut=stream_work.copy()\n",
    "for t in stream_cut:\n",
    "        #t.trim(t.stats['P_arrival']-Start_P_cut_time,t.stats['P_arrival']+End_P_cut_time)\n",
    "        t.trim(t.stats['P_arrival']-Start_P_cut_time,t.stats['P_arrival']+End_P_cut_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial no of traces =  70\n",
      "No of traces after STA-LTA=  44\n"
     ]
    }
   ],
   "source": [
    "##########################################################################\n",
    "# Now, there might be stations where arrival time is way off\n",
    "# or the data is not good. \n",
    "# So I run a simple sta-lta for the trimed traces \n",
    "# and set a threshold (5s) if the maximum time from sta-lta \n",
    "# is greater than that then i reject the trace \n",
    "# @ajay6763: WRITE ABOUT THE ARGUMENTS THAT GOES Into\n",
    "#            THE STA-LTA FUNCTION\n",
    "# Note: I have choosen 10 seconds as threshold such that if the difference\n",
    "# between the arrival time from 1D velocity model and the STA-LTA pick\n",
    "# is greater than it, then I assume something is not right with the station\n",
    "# and I simply throw the data for that station. \n",
    "##########################################################################\n",
    "print('Initial no of traces = ', len(stream_cut) )\n",
    "for t in stream_cut:\n",
    "        t.detrend\n",
    "        t.normalize\n",
    "        cft         = obspy.signal.trigger.recursive_sta_lta_py(t.data, int(1 * t.stats.sampling_rate), \n",
    "                      int(5 * t.stats.sampling_rate))\n",
    "        time        = np.arange(0, t.stats.npts / t.stats.sampling_rate, t.stats.delta)\n",
    "        ind         = np.argmax(cft)\n",
    "        if (abs(time[ind]-Start_P_cut_time) > 5 ):\n",
    "            stream_cut.remove(t)\n",
    "        else:\n",
    "            t.stats['STA_LTA_shift'] = time[ind]-Start_P_cut_time \n",
    "            \n",
    "print('No of traces after STA-LTA= ', len(stream_cut) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "##########################################################################\n",
    "# finding reference station\n",
    "# the the station in the middle of the array\n",
    "# I will take the mean of the distance and azimuth and take the station closest to it\n",
    "##########################################################################\n",
    "sta_dist=[]\n",
    "sta_azimuth=[]\n",
    "for tr in stream_cut:\n",
    "    sta_dist.append(tr.stats.Dist)\n",
    "    sta_azimuth.append(tr.stats.Azimuth)\n",
    "\n",
    "mean_dist = np.median(sta_dist)\n",
    "dist=np.array((mean_dist-sta_dist)**2);\n",
    "index_dist=dist.argmin(); \n",
    "            \n",
    "mean_azimuth = np.median(sta_azimuth)\n",
    "dist=np.array((mean_azimuth-sta_azimuth)**2);\n",
    "index_azimuth=dist.argmin(); \n",
    "\n",
    "Ref_station_index=index_dist\n",
    "##########################################################################\n",
    "# plotting reference station\n",
    "# If the station does not turn out to be in the centre of the array\n",
    "# you choose it in a ad-hoc fashion by changing the index of the reference\n",
    "# station above\n",
    "##########################################################################\n",
    "bp_lib.plot_array(stream_cut,event_long,event_lat,Array_name,Ref_station_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################################\n",
    "# Now will cross-correlat the all the treces \n",
    "# with the reference trace and save the \n",
    "# shift and correlation value which will \n",
    "# be used form 3D velocity varition corrections\n",
    "# and weight traces when stacking, respectively.\n",
    "##########################################################################\n",
    "ref_trace = stream_cut[Ref_station_index]\n",
    "for tr in stream_cut:\n",
    "    cc = obspy.signal.cross_correlation.correlate(ref_trace, tr, 10)\n",
    "    shift, value = obspy.signal.cross_correlation.xcorr_max(cc)\n",
    "    #xcorr_pick_correction(pick1, trace1, pick2, trace2, t_before, t_after, cc_maxlag, filter=None, filter_options={}, plot=False, filename=None)\n",
    "    #shift, value = obspy.signal.cross_correlation.xcorr_pick_correction(ref_trace.stats.P_arrival, ref_trace, \n",
    "    #    tr.stats.P_arrival, tr, 5, 5, 5, plot=False) #,filter=\"bandpass\",filter_options={'freqmin': bp_l, 'freqmax': bp_u})\n",
    "    tr.stats['Corr_coeff'] = shift/sps\n",
    "    tr.stats['Corr_shift']  = value\n",
    "    #print(\"shift\",shift)\n",
    "    #print(\"corr\",value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "count=0;\n",
    "for tr_ in stream_cut:\n",
    "    dist=((tr.stats.station_latitude-tr_.stats.station_latitude)**2 + \n",
    "         (tr.stats.station_longitude-tr_.stats.station_longitude)**2 )**0.2;\n",
    "    if ( dist <= 1):\n",
    "        count=count+1;\n",
    "    else:\n",
    "        continue\n",
    "    tr.stats['Station_weight'] = count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################################\n",
    "# Filtering traces\n",
    "##########################################################################\n",
    "stream_cut_filtered=stream_cut.copy()\n",
    "for tr in stream_cut_filtered:\n",
    "    tr.detrend\n",
    "    tr.filter('bandpass',freqmin=bp_l,freqmax=bp_u,corners=5)\n",
    "    tr.detrend\n",
    "    tr.normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of traces before cross-correlation threshold =  44\n",
      "No of traces after cross-correlation threshold =  44\n"
     ]
    }
   ],
   "source": [
    "##########################################################################\n",
    "# Selecting traces for BP. \n",
    "# Use can choose correlation threshold\n",
    "# If not then simple set threshold to 0\n",
    "# and all the traces will be used for in\n",
    "# back-projection\n",
    "##########################################################################\n",
    "stream_for_bp = stream_cut_filtered.copy()\n",
    "threshold_correlation=0.0\n",
    "print('No of traces before cross-correlation threshold = ', len(stream_for_bp))\n",
    "for tr in stream_for_bp:\n",
    "    if (abs(tr.stats.Corr_coeff) >= threshold_correlation):\n",
    "        #time = np.arange(0, tr.stats.npts / tr.stats.sampling_rate, tr.stats.delta)\n",
    "        #plt.plot(time,tr.data/np.max(tr.data))\n",
    "        count=count+1\n",
    "    else:\n",
    "        stream_for_bp.remove(tr)\n",
    "print('No of traces after cross-correlation threshold = ', len(stream_for_bp))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Station_weight",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\users\\kumar\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\obspy\\core\\util\\attribdict.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name, default)\u001b[0m\n\u001b[0;32m    127\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getitem__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    129\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\kumar\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\obspy\\core\\trace.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key, default)\u001b[0m\n\u001b[0;32m    234\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 235\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mStats\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getitem__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    236\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\kumar\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\obspy\\core\\util\\attribdict.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, name, default)\u001b[0m\n\u001b[0;32m     73\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 74\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     75\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Station_weight'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-dbf9e8b784d7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[1;31m# station density\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m         \u001b[1;31m#################################################################\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m         \u001b[0mcut\u001b[0m             \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mcut\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstats\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCorr_coeff\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstats\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mStation_weight\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m         \u001b[0mstack\u001b[0m           \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstack\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcut\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\kumar\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\obspy\\core\\util\\attribdict.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name, default)\u001b[0m\n\u001b[0;32m    128\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getitem__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 130\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    131\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m     \u001b[0m__setattr__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m__setitem__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: Station_weight"
     ]
    }
   ],
   "source": [
    "##########################################################################\n",
    "# doing the back-projection\n",
    "# beam variable is the \"beast\". \n",
    "# This will be an array who has size = [len[slat], len(stack_window)]\n",
    "# Basically this contains the traces from all the stations from an array \n",
    "# that are alligned according to the arrival-time of the P-wave from the each source\n",
    "# grid point.  \n",
    "##########################################################################\n",
    "beam=[];\n",
    "# looping throught all potential source location \n",
    "for j in range(len(slat)):\n",
    "    stack = []\n",
    "    # looping through all stations in the array \n",
    "    for t in stream_for_bp:\n",
    "        ##################################################################\n",
    "        # Taup part\n",
    "        ##################################################################\n",
    "        distance        = obspy.geodetics.locations2degrees(slat[j],slong[j],t.stats.station_latitude,t.stats.station_longitude)\n",
    "        ### travel time\n",
    "        arrivals        = model.get_travel_times(source_depth_in_km=event_depth,distance_in_degree=distance,phase_list=[\"P\"])\n",
    "        arr             = arrivals[0]\n",
    "        t_travel        = arr.time;\n",
    "        #################################################################\n",
    "        # total travel time adjusted for the correlation \n",
    "        # time shift\n",
    "        #################################################################\n",
    "        t_total         = origin_time + t_travel + t.stats.Corr_shift \n",
    "        #################################################################\n",
    "        # Cutting the trace starting from t_total above\n",
    "        # untill the stacking window in seconds defined at the top \n",
    "        #################################################################\n",
    "        cut             = []\n",
    "        cut,width,sign  = bp_lib.cut_window(t,t_total,stack_start,stack_end)\n",
    "        #################################################################\n",
    "        # Multiplying by the correlation and divifing by the\n",
    "        # station density \n",
    "        #################################################################\n",
    "        cut             = (cut*t.stats.Corr_coeff)/t.stats.Station_weight\n",
    "        stack           = np.append(stack,cut)\n",
    "        \n",
    "    #####################################################################\n",
    "    stack_reshaped      = np.reshape(stack, (len(stream_for_bp), width))\n",
    "    sum_stack           = np.sum(stack_reshaped,axis=0)\n",
    "    beam                = np.append(beam,sum_stack)\n",
    "    print(\"Progress =\",((j/len(slat))*100),\"%\" )\n",
    "##########################################################################\n",
    "## reshaping beam\n",
    "beam_reshaped           = np.reshape(beam, (len(slat), width))\n",
    "##########################################################################\n",
    "# saving beam \n",
    "file_save = 'beam_'+str(bp_l)+'_'+str(bp_u)+'_'+str(Array_name)+'.dat'\n",
    "np.savetxt(file_save,beam_reshaped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################################\n",
    "## calculating STF from the waveforms\n",
    "STF_start           = 0\n",
    "STF_end             = 60\n",
    "stf                 = []\n",
    "for t in stream_for_bp:\n",
    "        ##################################################################\n",
    "        if(abs(t.stats.Corr_coeff) >= threshold_correlation):\n",
    "            # cut,paste,and stack\n",
    "            stf            = []\n",
    "            cut            = []\n",
    "            cut,width,sign = bp_lib.cut_window(t,t.stats.P_arrival+t.stats.Corr_shift,STF_start,STF_end)\n",
    "            stf            = (cut*t.stats.Corr_coeff)/t.stats.Station_weight\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "#Taking square becaouse we are interested in the power\n",
    "stf=stf**2 \n",
    "#Moving time window average \n",
    "stf_averaged  = bp_lib.moving_average_time(stf[:],smooth_time_window*sps)\n",
    "#Normalizing \n",
    "stf_averaged  = stf_averaged/np.max(stf_averaged)\n",
    "stf_time      = np.arange(0, len(stf_averaged) / ref_trace.stats.sampling_rate, ref_trace.stats.delta)\n",
    "STF_array     = np.copy(stf_time)\n",
    "STF_array     = np.column_stack((STF_array,stf_averaged)) #\n",
    "#################\n",
    "#plotting\n",
    "#plt.plot(STF_array[:,0],STF_array[:,1])\n",
    "#plt.xlabel('Time (s)')\n",
    "#plt.ylabel('Normalized Amplitude')\n",
    "#plt.savefig(str(Array_name)+'_STF.png')\n",
    "#saving STF \n",
    "file_save    = 'STF_'+str(bp_l)+'_'+str(bp_u)+'_'+str(Array_name)+'.dat'\n",
    "np.savetxt(file_save,STF_array)\n",
    "\n",
    "m,n          = np.shape(beam_reshaped)\n",
    "# space wise smoothening\n",
    "stack_start  = 0\n",
    "stack_end    = 60\n",
    "# space wise smoothening\n",
    "beam_averaged_time=np.zeros((m,stack_end-stack_start))\n",
    "for i in range(stack_end-stack_start):\n",
    "    beam_averaged_time[:,i] = bp_lib.moving_average_time_beam(beam_reshaped[:,i*sps:(i+smooth_time_window-1)*sps]**2)\n",
    "beam_averaged_time=beam_averaged_time/np.max(beam_averaged_time)\n",
    "\n",
    "#bp_lib.plot_results(beam_averaged_time,STF_array,event_long,event_lat,Array_name,slong,slat,stack_start,stack_end)\n",
    "\n",
    "\n",
    "# Cumulative energy\n",
    "temp     =np.sum(beam_averaged_time[:,stack_start:stack_end],axis=1)\n",
    "np.size(temp)\n",
    "m,n=np.shape(beam_averaged_time)\n",
    "cumulative_energy=np.zeros((m,3))\n",
    "cumulative_energy[:,2]=temp/np.max(temp)\n",
    "cumulative_energy[:,0]=slong\n",
    "cumulative_energy[:,1]=slat\n",
    "\n",
    "file_save='cumulative_energy_'+str(bp_l)+'_'+str(bp_u)+'_'+str(Array_name)+'.dat'\n",
    "np.savetxt(file_save,cumulative_energy)\n",
    "\n",
    "m,n=np.shape(beam_averaged_time)\n",
    "peak_energy=np.zeros((n,4))\n",
    "for i in range(n):\n",
    "    ind              = np.argmax(beam_averaged_time[:,i])\n",
    "    peak_energy[i,0] = i\n",
    "    peak_energy[i,1] = slong[ind]\n",
    "    peak_energy[i,2] = slat[ind]\n",
    "    peak_energy[i,3] = beam_averaged_time[ind,i]\n",
    "\n",
    "file_save='Peak_energy_'+str(bp_l)+'_'+str(bp_u)+'_'+str(Array_name)+'.dat'\n",
    "np.savetxt(file_save,peak_energy)\n",
    "\n",
    "colors=range(0,n,1)\n",
    "fig, ax           = plt.subplots(1, 2, sharex=False, sharey=False,figsize=(10, 6))\n",
    "tri               = Triangulation(cumulative_energy[:,0],cumulative_energy[:,1])\n",
    "energy            = ax[0].tricontourf(tri, cumulative_energy[:,2],cmap='hot',levels=np.arange(0, 1,0.1))\n",
    "event             = ax[0].plot(event_long,event_lat,'*',markersize=20)\n",
    "cmap              = plt.get_cmap('cubehelix', 10)\n",
    "cmap.set_under('gray')\n",
    "peak              = ax[0].scatter(peak_energy[:,1],peak_energy[:,2],c=peak_energy[:,0],s=peak_energy[:,3]*500,cmap=cmap,vmin=0,vmax=peak_energy[:,0].max())\n",
    "fig.colorbar(energy,ax=ax[0],label='Cumulative energy',orientation='horizontal')\n",
    "fig.colorbar(peak,ax=ax[0],label='Peak energy',orientation='vertical')\n",
    "\n",
    "stf_combined     = ax[1].plot(STF_array[:,0],STF_array[:,1])\n",
    "stf              = ax[1].plot(STF_array[:,0],STF_array[:,1])\n",
    "\n",
    "ax[1].set_xlabel('Time (s)')\n",
    "ax[1].set_ylabel('Normalized Amplitude')\n",
    "fig.savefig('BP_Peak_energy_'+str(bp_l)+'_'+str(bp_u)+'_'+str(Array_name)+'.png')\n",
    "\n",
    "\n",
    "print(\"Progress back-projection DONE!!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
